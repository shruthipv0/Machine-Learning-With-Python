# Machine-Learning-With-Python

# My Machine Learning Notes

These are my notes on **Machine Learning algorithms** including both **Supervised** and **Unsupervised** learning. I have learned and worked on coding projects covering various topics, and below is a summary of my work:

## Supervised Learning:
1. **Linear Regression**
   - A regression model used to predict a continuous target variable based on one or more predictor variables.
   - Key concepts: slope, intercept, coefficients, least squares method, and evaluation metrics like RMSE, R-squared.
   
2. **Logistic Regression**
   - A classification model used for binary or multi-class classification problems, predicting probabilities of outcomes.
   - Key concepts: sigmoid function, odds, log-odds, decision boundaries, and evaluation metrics like accuracy, precision, recall, and F1-score.

3. **Decision Trees**
   - A non-linear classification and regression model that splits data into subsets based on feature values.
   - Key concepts: nodes, leaves, Gini impurity, and information gain.
   
4. **Random Forest**
   - An ensemble method that creates a "forest" of decision trees and combines their predictions.
   - Key concepts: bagging, bootstrapping, and feature importance.

5. **Support Vector Machines (SVM)**
   - A classification method that finds the optimal hyperplane that best separates classes in high-dimensional space.
   - Key concepts: margin, kernels, and support vectors.

## Unsupervised Learning:
1. **K-Means Clustering**
   - A clustering algorithm that partitions data into k distinct clusters based on feature similarities.
   - Key concepts: centroids, Euclidean distance, inertia, and elbow method.
   
2. **Hierarchical Clustering**
   - A clustering method that builds a tree-like structure to represent data in a hierarchy of clusters.
   - Key concepts: dendrogram, agglomerative, divisive methods, and linkage criteria.

3. **Principal Component Analysis (PCA)**
   - A dimensionality reduction technique that transforms high-dimensional data into lower dimensions while retaining most of the variance.
   - Key concepts: eigenvectors, eigenvalues, variance explained, and components.

4. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**
   - A density-based clustering algorithm that can identify clusters of varying shapes and outliers.
   - Key concepts: epsilon, min_samples, core points, border points, and noise.

## Projects
I have worked on various coding projects using **Python**, **scikit-learn**, **TensorFlow**, and **Keras** to implement these algorithms. The projects include real-world datasets for tasks like:
- **Prediction (Supervised Learning)**: Predicting house prices, customer churn, etc.
- **Clustering (Unsupervised Learning)**: Customer segmentation, anomaly detection, etc.
  
## Contribute or Suggest
Feel free to explore and learn more from these notes.  
If you have any suggestions or notice anything that is incorrect, please let me know!

## Acknowledgement 

These notes are inspired by the IBM Machine Learning with Python module from the __IBM Generative AI Engineering Course__.
